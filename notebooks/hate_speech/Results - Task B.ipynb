{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-combi.json\t\t\t  beto.json\n",
      "bert-hier.json\t\t\t  roberta-combi.json\n",
      "bert.json\t\t\t  roberta-hier.json\n",
      "bertweet-combi.json\t\t  roberta.json\n",
      "bertweet-hier.json\t\t  robertuito-combi.json\n",
      "bertweet.json\t\t\t  robertuito-hierarchical-gamma-0.1.json\n",
      "beto-combi.json\t\t\t  robertuito-hierarchical-gamma-0.json\n",
      "beto-hierarchical-gamma-0.1.json  robertuito.json\n",
      "beto-hierarchical-gamma-0.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../../evaluations/hate_speech/task_b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10 beto evaluations\n",
      "We have 10 beto-pred evaluations\n",
      "We have 10 beto-hier evaluations\n",
      "We have 10 beto-combi evaluations\n",
      "We have 10 robertuito evaluations\n",
      "We have 10 robertuito-hier evaluations\n",
      "We have 10 robertuito-combi evaluations\n",
      "We have 10 bert evaluations\n",
      "We have 10 bert-hier evaluations\n",
      "We have 10 bert-combi evaluations\n",
      "We have 10 roberta evaluations\n",
      "We have 10 roberta-hier evaluations\n",
      "We have 10 roberta-combi evaluations\n",
      "We have 10 bertweet evaluations\n",
      "We have 10 bertweet-hier evaluations\n",
      "We have 10 bertweet-combi evaluations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hs_f1</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>ag_f1</th>\n",
       "      <th>emr</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>macro_hs_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto mean</th>\n",
       "      <td>0.741</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-pred mean</th>\n",
       "      <td>0.740</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-hier mean</th>\n",
       "      <td>0.735</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beto-combi mean</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito mean</th>\n",
       "      <td>0.766</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-hier mean</th>\n",
       "      <td>0.759</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robertuito-combi mean</th>\n",
       "      <td>0.771</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert mean</th>\n",
       "      <td>0.638</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-hier mean</th>\n",
       "      <td>0.642</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-combi mean</th>\n",
       "      <td>0.644</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta mean</th>\n",
       "      <td>0.634</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-hier mean</th>\n",
       "      <td>0.637</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta-combi mean</th>\n",
       "      <td>0.636</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertweet mean</th>\n",
       "      <td>0.658</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertweet-hier mean</th>\n",
       "      <td>0.656</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertweet-combi mean</th>\n",
       "      <td>0.666</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       hs_f1  tr_f1  ag_f1   emr  macro_f1  macro_hs_f1_score\n",
       "beto mean              0.741  0.765  0.688 0.685     0.731              0.771\n",
       "beto-pred mean         0.740  0.762  0.679 0.676     0.727              0.766\n",
       "beto-hier mean         0.735  0.758  0.674 0.703     0.722              0.776\n",
       "beto-combi mean        0.742  0.763  0.668 0.698     0.724              0.776\n",
       "robertuito mean        0.766  0.792  0.698 0.710     0.752              0.800\n",
       "robertuito-hier mean   0.759  0.795  0.681 0.706     0.745              0.793\n",
       "robertuito-combi mean  0.771  0.808  0.697 0.723     0.759              0.804\n",
       "bert mean              0.638  0.600  0.443 0.380     0.560              0.512\n",
       "bert-hier mean         0.642  0.592  0.451 0.388     0.562              0.521\n",
       "bert-combi mean        0.644  0.593  0.442 0.398     0.560              0.531\n",
       "roberta mean           0.634  0.578  0.454 0.365     0.555              0.487\n",
       "roberta-hier mean      0.637  0.572  0.456 0.370     0.555              0.490\n",
       "roberta-combi mean     0.636  0.576  0.442 0.377     0.551              0.500\n",
       "bertweet mean          0.658  0.629  0.462 0.426     0.583              0.567\n",
       "bertweet-hier mean     0.656  0.617  0.450 0.423     0.574              0.555\n",
       "bertweet-combi mean    0.666  0.634  0.445 0.450     0.582              0.589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "evaluations = {\n",
    "\n",
    "}\n",
    "\n",
    "for model_name, path in [\n",
    "    ('beto', '../../evaluations/hate_speech/task_b/beto.json'),\n",
    "    ('beto-pred', '../../evaluations/hate_speech/task_b/beto_pred.json'),\n",
    "    ('beto-hier', '../../evaluations/hate_speech/task_b/beto-hierarchical-gamma-0.1.json'),\n",
    "    ('beto-combi', '../../evaluations/hate_speech/task_b/beto-combi.json'),\n",
    "    ('robertuito', '../../evaluations/hate_speech/task_b/robertuito.json'),\n",
    "    ('robertuito-hier', '../../evaluations/hate_speech/task_b/robertuito-hierarchical-gamma-0.1.json'),\n",
    "    ('robertuito-combi', '../../evaluations/hate_speech/task_b/robertuito-combi.json'),\n",
    "    ('bert', '../../evaluations/hate_speech/task_b/bert.json'),\n",
    "    ('bert-hier', '../../evaluations/hate_speech/task_b/bert-hier.json'),\n",
    "    ('bert-combi', '../../evaluations/hate_speech/task_b/bert-combi.json'),\n",
    "    ('roberta', '../../evaluations/hate_speech/task_b/roberta.json'),\n",
    "    ('roberta-hier', '../../evaluations/hate_speech/task_b/roberta-hier.json'),\n",
    "    ('roberta-combi', '../../evaluations/hate_speech/task_b/roberta-combi.json'),\n",
    "    ('bertweet', '../../evaluations/hate_speech/task_b/bertweet.json'),\n",
    "    ('bertweet-hier', '../../evaluations/hate_speech/task_b/bertweet-hier.json'),\n",
    "    ('bertweet-combi', '../../evaluations/hate_speech/task_b/bertweet-combi.json'),\n",
    "    ]:\n",
    "    with open(path) as f:\n",
    "        evaluations[model_name] = json.load(f)\n",
    "\n",
    "\n",
    "for key, evals in evaluations.items():\n",
    "    print(f\"We have {len(evals['evaluations']['hate_speech'])} {key} evaluations\")\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for model_name, model_results in evaluations.items():\n",
    "    model_evaluations = model_results[\"evaluations\"][\"hate_speech\"]\n",
    "    \n",
    "    if not model_evaluations:\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(model_evaluations)\n",
    "\n",
    "    df.columns = [x.split(\"_\", 1)[1] if \"_\" in x else x for x in df.columns]\n",
    "    \n",
    "    mean_df = pd.DataFrame({\n",
    "        f\"{model_name} mean\": df.mean(), \n",
    "        f\"{model_name} std\": df.std()\n",
    "    })\n",
    "    dfs.append(mean_df)\n",
    "\n",
    "result_df = pd.concat(dfs, axis=1)\n",
    "index = [\n",
    "    'hs_f1', 'tr_f1',\n",
    "    'ag_f1', 'emr', \n",
    "    'macro_f1', 'macro_hs_f1_score',\n",
    "]\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "show_df = result_df.loc[index, [c for c in result_df.columns if \"std\" not in c]].T\n",
    "#print(show_df.to_latex())\n",
    "\n",
    "show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "metric = \"eval_emr\"\n",
    "\n",
    "combi = {\n",
    "    \"f1\": [evaluation[\"eval_macro_f1\"] for evaluation in evaluations[\"beto-combi\"][\"evaluations\"][\"hate_speech\"]],\n",
    "    \"emr\": [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto-combi\"][\"evaluations\"][\"hate_speech\"]]\n",
    "}\n",
    "\n",
    "hier = {\n",
    "    \"f1\": [evaluation[\"eval_macro_f1\"] for evaluation in evaluations[\"beto-hier\"][\"evaluations\"][\"hate_speech\"]],\n",
    "    \"emr\": [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto-hier\"][\"evaluations\"][\"hate_speech\"]]\n",
    "}\n",
    "\n",
    "\n",
    "standard = {\n",
    "    \"f1\": [evaluation[\"test_macro_f1\"] for evaluation in evaluations[\"beto\"][\"evaluations\"][\"hate_speech\"]],\n",
    "    \"emr\": [evaluation[\"test_emr\"] for evaluation in evaluations[\"beto\"][\"evaluations\"][\"hate_speech\"]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos un test de Kruskal para ver si la diferencia entre las medias es significativa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=0.6509018036072056, pvalue=0.7222016381935228)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal(standard[\"emr\"], hier[\"emr\"], combi[\"emr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=3.6567741935483866, pvalue=0.16067250810281022)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal(standard[\"f1\"], hier[\"f1\"], combi[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=26.5, pvalue=0.08186862373064437)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.mannwhitneyu(standard[\"emr\"], hier[\"emr\"], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No lo es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=10.860138146167559, pvalue=0.004382793059181017)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "combi_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito-combi\"][\"evaluations\"][\"hate_speech\"]]\n",
    "hier_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito-hier\"][\"evaluations\"][\"hate_speech\"]]\n",
    "standard_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito\"][\"evaluations\"][\"hate_speech\"]]\n",
    "\n",
    "scipy.stats.kruskal(standard_emr, hier_emr, combi_emr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de robertuito s√≠! wtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
