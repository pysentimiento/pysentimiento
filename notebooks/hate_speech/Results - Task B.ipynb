{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beto-combi.json\t\t\t  robertuito-combi.json\n",
      "beto-hierarchical-gamma-0.1.json  robertuito-hierarchical-gamma-0.1.json\n",
      "beto-hierarchical-gamma-0.json\t  robertuito-hierarchical-gamma-0.json\n",
      "beto.json\t\t\t  robertuito.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../../evaluations/hate_speech/task_b/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10 beto evaluations\n",
      "We have 10 beto-hier evaluations\n",
      "We have 10 beto-combi evaluations\n",
      "We have 10 robertuito evaluations\n",
      "We have 10 robertuito-hier evaluations\n",
      "We have 10 robertuito-combi evaluations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beto mean</th>\n",
       "      <th>beto-hier mean</th>\n",
       "      <th>beto-combi mean</th>\n",
       "      <th>robertuito mean</th>\n",
       "      <th>robertuito-hier mean</th>\n",
       "      <th>robertuito-combi mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hs_f1</th>\n",
       "      <td>0.741171</td>\n",
       "      <td>0.734925</td>\n",
       "      <td>0.742136</td>\n",
       "      <td>0.765693</td>\n",
       "      <td>0.759455</td>\n",
       "      <td>0.770661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_precision</th>\n",
       "      <td>0.712582</td>\n",
       "      <td>0.743658</td>\n",
       "      <td>0.725866</td>\n",
       "      <td>0.761301</td>\n",
       "      <td>0.749329</td>\n",
       "      <td>0.768850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs_recall</th>\n",
       "      <td>0.777879</td>\n",
       "      <td>0.727576</td>\n",
       "      <td>0.761515</td>\n",
       "      <td>0.772424</td>\n",
       "      <td>0.773939</td>\n",
       "      <td>0.774697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr_f1</th>\n",
       "      <td>0.765226</td>\n",
       "      <td>0.758053</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.792220</td>\n",
       "      <td>0.794922</td>\n",
       "      <td>0.808406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ag_f1</th>\n",
       "      <td>0.687683</td>\n",
       "      <td>0.674417</td>\n",
       "      <td>0.667843</td>\n",
       "      <td>0.697813</td>\n",
       "      <td>0.680564</td>\n",
       "      <td>0.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_hs_f1_score</th>\n",
       "      <td>0.771392</td>\n",
       "      <td>0.776030</td>\n",
       "      <td>0.776321</td>\n",
       "      <td>0.799745</td>\n",
       "      <td>0.792895</td>\n",
       "      <td>0.804141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emr_no_gating</th>\n",
       "      <td>0.684063</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>0.709688</td>\n",
       "      <td>0.692187</td>\n",
       "      <td>0.723125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emr</th>\n",
       "      <td>0.684812</td>\n",
       "      <td>0.703313</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>0.709937</td>\n",
       "      <td>0.705938</td>\n",
       "      <td>0.723125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_f1</th>\n",
       "      <td>0.731360</td>\n",
       "      <td>0.722465</td>\n",
       "      <td>0.724473</td>\n",
       "      <td>0.751909</td>\n",
       "      <td>0.744980</td>\n",
       "      <td>0.758556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   beto mean  beto-hier mean  beto-combi mean  \\\n",
       "hs_f1               0.741171        0.734925         0.742136   \n",
       "hs_precision        0.712582        0.743658         0.725866   \n",
       "hs_recall           0.777879        0.727576         0.761515   \n",
       "tr_f1               0.765226        0.758053         0.763441   \n",
       "ag_f1               0.687683        0.674417         0.667843   \n",
       "macro_hs_f1_score   0.771392        0.776030         0.776321   \n",
       "emr_no_gating       0.684063        0.673875         0.697625   \n",
       "emr                 0.684812        0.703313         0.697625   \n",
       "macro_f1            0.731360        0.722465         0.724473   \n",
       "\n",
       "                   robertuito mean  robertuito-hier mean  \\\n",
       "hs_f1                     0.765693              0.759455   \n",
       "hs_precision              0.761301              0.749329   \n",
       "hs_recall                 0.772424              0.773939   \n",
       "tr_f1                     0.792220              0.794922   \n",
       "ag_f1                     0.697813              0.680564   \n",
       "macro_hs_f1_score         0.799745              0.792895   \n",
       "emr_no_gating             0.709688              0.692187   \n",
       "emr                       0.709937              0.705938   \n",
       "macro_f1                  0.751909              0.744980   \n",
       "\n",
       "                   robertuito-combi mean  \n",
       "hs_f1                           0.770661  \n",
       "hs_precision                    0.768850  \n",
       "hs_recall                       0.774697  \n",
       "tr_f1                           0.808406  \n",
       "ag_f1                           0.696601  \n",
       "macro_hs_f1_score               0.804141  \n",
       "emr_no_gating                   0.723125  \n",
       "emr                             0.723125  \n",
       "macro_f1                        0.758556  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "evaluations = {\n",
    "\n",
    "}\n",
    "\n",
    "for model_name, path in [\n",
    "    ('beto', '../../evaluations/hate_speech/task_b/beto.json'),\n",
    "    ('beto-hier', '../../evaluations/hate_speech/task_b/beto-hierarchical-gamma-0.1.json'),\n",
    "    #('beto-hier-zero', '../../evaluations/hate_speech/task_b/beto-hierarchical-gamma-0.json'),\n",
    "    ('beto-combi', '../../evaluations/hate_speech/task_b/beto-combi.json'),\n",
    "    ('robertuito', '../../evaluations/hate_speech/task_b/robertuito.json'),\n",
    "    ('robertuito-hier', '../../evaluations/hate_speech/task_b/robertuito-hierarchical-gamma-0.1.json'),\n",
    "    #('robertuito-hier-zero', '../../evaluations/hate_speech/task_b/robertuito-hierarchical-gamma-0.json'),\n",
    "    ('robertuito-combi', '../../evaluations/hate_speech/task_b/robertuito-combi.json'),\n",
    "    ]:\n",
    "    with open(path) as f:\n",
    "        evaluations[model_name] = json.load(f)\n",
    "\n",
    "\n",
    "for key, evals in evaluations.items():\n",
    "    print(f\"We have {len(evals['evaluations']['hate_speech'])} {key} evaluations\")\n",
    "\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for model_name, model_results in evaluations.items():\n",
    "    model_evaluations = model_results[\"evaluations\"][\"hate_speech\"]\n",
    "    \n",
    "    if not model_evaluations:\n",
    "        continue\n",
    "    \n",
    "    df = pd.DataFrame(model_evaluations)\n",
    "\n",
    "    df.columns = [x.split(\"_\", 1)[1] if \"_\" in x else x for x in df.columns]\n",
    "    \n",
    "    mean_df = pd.DataFrame({\n",
    "        f\"{model_name} mean\": df.mean(), \n",
    "        f\"{model_name} std\": df.std()\n",
    "    })\n",
    "    dfs.append(mean_df)\n",
    "\n",
    "result_df = pd.concat(dfs, axis=1)\n",
    "index = [\n",
    "    'hs_f1', 'hs_precision', 'hs_recall', 'tr_f1',\n",
    "    'ag_f1', 'macro_hs_f1_score',\n",
    "    'emr_no_gating', 'emr', \n",
    "    'macro_f1',\n",
    "]\n",
    "result_df.loc[index, [c for c in result_df.columns if \"std\" not in c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "combi_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto-combi\"][\"evaluations\"][\"hate_speech\"]]\n",
    "hier_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto-hier\"][\"evaluations\"][\"hate_speech\"]]\n",
    "standard_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"beto\"][\"evaluations\"][\"hate_speech\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos un test de Kruskal para ver si la diferencia entre las medias es significativa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=3.4920080142475607, pvalue=0.17446973214802494)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kruskal(standard_emr, hier_emr, combi_emr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No lo es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=10.860138146167559, pvalue=0.004382793059181017)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "combi_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito-combi\"][\"evaluations\"][\"hate_speech\"]]\n",
    "hier_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito-hier\"][\"evaluations\"][\"hate_speech\"]]\n",
    "standard_emr = [evaluation[\"eval_emr\"] for evaluation in evaluations[\"robertuito\"][\"evaluations\"][\"hate_speech\"]]\n",
    "\n",
    "scipy.stats.kruskal(standard_emr, hier_emr, combi_emr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de robertuito s√≠! wtf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "387abc9bc94d8eb1bd0148a5d4cb2bf99bc3b40fa501b808e2b508b4f65ed831"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('pysentimiento-bwlKzHxB-py3.7': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
